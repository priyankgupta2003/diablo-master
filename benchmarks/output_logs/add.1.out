Number of nodes =  5
Number of executors =  49
myHadoop: Setting MH_IPOIB_TRANSFORM='s/\([^.]*\).*$/\1.ib.cluster/' from myhadoop.conf
myHadoop: Setting MH_SCRATCH_DIR=/scratch/$USER/job_$SLURM_JOBID from myhadoop.conf
myHadoop: Using HADOOP_HOME=/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2
myHadoop: Using MH_SCRATCH_DIR=/scratch/txk6771/job_10051764
myHadoop: Using JAVA_HOME=/cm/shared/apps/spack/cpu/opt/spack/linux-centos8-zen/gcc-8.3.1/openjdk-11.0.2-k5ezeyjgjeqmehyvrmmpymaguuf2qzsk
myHadoop: Generating Hadoop configuration in directory in /home/txk6771/expansecluster...
myHadoop: Backing up old config dir to /home/txk6771/expansecluster.51...
renamed '/home/txk6771/expansecluster' -> '/home/txk6771/expansecluster.51'
cp: -r not specified; omitting directory '/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/etc/hadoop/shellprofile.d'
myHadoop: Designating exp-5-29.ib.cluster as master node (namenode, secondary namenode, and jobtracker)
myHadoop: The following nodes will be slaves (datanode, tasktracer):
exp-5-29.ib.cluster
exp-5-30.ib.cluster
exp-5-31.ib.cluster
exp-5-32.ib.cluster
exp-5-33.ib.cluster
WARNING: /scratch/txk6771/job_10051764/pids does not exist. Creating.
WARNING: /scratch/txk6771/job_10051764/logs does not exist. Creating.
2022-02-27 22:40:04,687 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = exp-5-29/198.202.102.242
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /home/txk6771/expansecluster:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/checker-qual-2.5.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/gson-2.2.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-2.9.10.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-codec-1.11.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-io-2.5.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-cli-1.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-lang3-3.7.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/log4j-1.2.17.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/guava-27.0-jre.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jersey-core-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/paranamer-2.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-text-1.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jsp-api-2.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/asm-5.0.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/failureaccess-1.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/avro-1.7.7.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jsch-0.1.55.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jersey-server-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-compress-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/json-smart-2.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jersey-json-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/dnsjava-2.1.7.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jettison-1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/re2j-1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/lib/commons-net-3.6.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/hadoop-nfs-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/common/hadoop-kms-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-text-1.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/guice-4.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/fst-2.50.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/javax.inject-1.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/expanse/lustre/projects/uot166/fegaras/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 11.0.2
************************************************************/
2022-02-27 22:40:04,693 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-02-27 22:40:04,748 INFO namenode.NameNode: createNameNode [-format]
2022-02-27 22:40:05,065 INFO common.Util: Assuming 'file' scheme for path /scratch/txk6771/job_10051764/namenode_data in configuration.
2022-02-27 22:40:05,066 INFO common.Util: Assuming 'file' scheme for path /scratch/txk6771/job_10051764/namenode_data in configuration.
Formatting using clusterid: CID-12f64e6e-2226-4353-9096-c093fb808fcb
2022-02-27 22:40:05,088 INFO namenode.FSEditLog: Edit logging is async:true
2022-02-27 22:40:05,109 INFO namenode.FSNamesystem: KeyProvider: null
2022-02-27 22:40:05,110 INFO namenode.FSNamesystem: fsLock is fair: true
2022-02-27 22:40:05,110 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2022-02-27 22:40:05,142 INFO namenode.FSNamesystem: fsOwner             = txk6771 (auth:SIMPLE)
2022-02-27 22:40:05,142 INFO namenode.FSNamesystem: supergroup          = supergroup
2022-02-27 22:40:05,142 INFO namenode.FSNamesystem: isPermissionEnabled = true
2022-02-27 22:40:05,142 INFO namenode.FSNamesystem: HA Enabled: false
2022-02-27 22:40:05,228 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-02-27 22:40:05,235 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2022-02-27 22:40:05,235 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2022-02-27 22:40:05,238 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2022-02-27 22:40:05,238 INFO blockmanagement.BlockManager: The block deletion will start around 2022 Feb 27 22:40:05
2022-02-27 22:40:05,239 INFO util.GSet: Computing capacity for map BlocksMap
2022-02-27 22:40:05,239 INFO util.GSet: VM type       = 64-bit
2022-02-27 22:40:05,240 INFO util.GSet: 2.0% max memory 30.0 GB = 613.8 MB
2022-02-27 22:40:05,240 INFO util.GSet: capacity      = 2^26 = 67108864 entries
2022-02-27 22:40:05,274 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
2022-02-27 22:40:05,274 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
2022-02-27 22:40:05,279 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2022-02-27 22:40:05,279 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2022-02-27 22:40:05,279 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2022-02-27 22:40:05,279 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2022-02-27 22:40:05,279 INFO blockmanagement.BlockManager: defaultReplication         = 3
2022-02-27 22:40:05,279 INFO blockmanagement.BlockManager: maxReplication             = 512
2022-02-27 22:40:05,279 INFO blockmanagement.BlockManager: minReplication             = 1
2022-02-27 22:40:05,279 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
2022-02-27 22:40:05,280 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2022-02-27 22:40:05,280 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
2022-02-27 22:40:05,280 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2022-02-27 22:40:05,295 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2022-02-27 22:40:05,295 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2022-02-27 22:40:05,295 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2022-02-27 22:40:05,295 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2022-02-27 22:40:05,302 INFO util.GSet: Computing capacity for map INodeMap
2022-02-27 22:40:05,302 INFO util.GSet: VM type       = 64-bit
2022-02-27 22:40:05,302 INFO util.GSet: 1.0% max memory 30.0 GB = 306.9 MB
2022-02-27 22:40:05,302 INFO util.GSet: capacity      = 2^25 = 33554432 entries
2022-02-27 22:40:05,316 INFO namenode.FSDirectory: ACLs enabled? false
2022-02-27 22:40:05,316 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
2022-02-27 22:40:05,316 INFO namenode.FSDirectory: XAttrs enabled? true
2022-02-27 22:40:05,316 INFO namenode.NameNode: Caching file names occurring more than 10 times
2022-02-27 22:40:05,320 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2022-02-27 22:40:05,322 INFO snapshot.SnapshotManager: SkipList is disabled
2022-02-27 22:40:05,325 INFO util.GSet: Computing capacity for map cachedBlocks
2022-02-27 22:40:05,325 INFO util.GSet: VM type       = 64-bit
2022-02-27 22:40:05,325 INFO util.GSet: 0.25% max memory 30.0 GB = 76.7 MB
2022-02-27 22:40:05,325 INFO util.GSet: capacity      = 2^23 = 8388608 entries
2022-02-27 22:40:05,335 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2022-02-27 22:40:05,335 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2022-02-27 22:40:05,335 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2022-02-27 22:40:05,338 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
2022-02-27 22:40:05,338 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2022-02-27 22:40:05,339 INFO util.GSet: Computing capacity for map NameNodeRetryCache
2022-02-27 22:40:05,339 INFO util.GSet: VM type       = 64-bit
2022-02-27 22:40:05,340 INFO util.GSet: 0.029999999329447746% max memory 30.0 GB = 9.2 MB
2022-02-27 22:40:05,340 INFO util.GSet: capacity      = 2^20 = 1048576 entries
2022-02-27 22:40:05,357 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1170934726-198.202.102.242-1646030405352
2022-02-27 22:40:05,369 INFO common.Storage: Storage directory /scratch/txk6771/job_10051764/namenode_data has been successfully formatted.
2022-02-27 22:40:05,397 INFO namenode.FSImageFormatProtobuf: Saving image file /scratch/txk6771/job_10051764/namenode_data/current/fsimage.ckpt_0000000000000000000 using no compression
2022-02-27 22:40:05,479 INFO namenode.FSImageFormatProtobuf: Image file /scratch/txk6771/job_10051764/namenode_data/current/fsimage.ckpt_0000000000000000000 of size 402 bytes saved in 0 seconds .
2022-02-27 22:40:05,494 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
2022-02-27 22:40:05,498 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.
2022-02-27 22:40:05,499 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at exp-5-29/198.202.102.242
************************************************************/
myHadoop:  
myHadoop: Enabling experimental Spark support
myHadoop: Using SPARK_CONF_DIR=/home/txk6771/expansecluster/spark
myHadoop:  
To use Spark, you will want to type the following commands:"
  source /home/txk6771/expansecluster/spark/spark-env.sh
  myspark start
Starting namenodes on [exp-5-29.ib.cluster]
exp-5-29: could not open any host key
exp-5-29: ssh_keysign: no reply
exp-5-29: sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
Starting datanodes
WARNING: HADOOP_SECURE_DN_PID_DIR has been replaced by HADOOP_SECURE_PID_DIR. Using value of HADOOP_SECURE_DN_PID_DIR.
localhost: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
localhost: @    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
localhost: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
localhost: IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
localhost: Someone could be eavesdropping on you right now (man-in-the-middle attack)!
localhost: It is also possible that a host key has just been changed.
localhost: The fingerprint for the ED25519 key sent by the remote host is
localhost: SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI.
localhost: Please contact your system administrator.
localhost: Add correct host key in /home/txk6771/.ssh/known_hosts to get rid of this message.
localhost: Offending ED25519 key in /home/txk6771/.ssh/known_hosts:1
localhost: Password authentication is disabled to avoid man-in-the-middle attacks.
localhost: Keyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.
localhost: could not open any host key
localhost: ssh_keysign: no reply
localhost: sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
localhost: WARNING: HADOOP_SECURE_DN_PID_DIR has been replaced by HADOOP_SECURE_PID_DIR. Using value of HADOOP_SECURE_DN_PID_DIR.
Starting secondary namenodes [exp-5-29.ib.cluster]
exp-5-29: could not open any host key
exp-5-29: ssh_keysign: no reply
exp-5-29: sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
mySpark: Using /home/txk6771/expansecluster/spark/slaves as our slaves file
mySpark: Reading in /home/txk6771/expansecluster/spark/spark-env.sh as our slaves file
starting org.apache.spark.deploy.master.Master, logging to /scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.master.Master-1-exp-5-29.out
mySpark: Starting worker on exp-5-29.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark start org.apache.spark.deploy.worker.Worker 1 spark://exp-5-29.ib.cluster:7077
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
starting org.apache.spark.deploy.worker.Worker, logging to /scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-29.out
mySpark: Starting worker on exp-5-30.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark start org.apache.spark.deploy.worker.Worker 1 spark://exp-5-29.ib.cluster:7077
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
starting org.apache.spark.deploy.worker.Worker, logging to /scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-30.out
mySpark: Starting worker on exp-5-31.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark start org.apache.spark.deploy.worker.Worker 1 spark://exp-5-29.ib.cluster:7077
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
starting org.apache.spark.deploy.worker.Worker, logging to /scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-31.out
mySpark: Starting worker on exp-5-32.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark start org.apache.spark.deploy.worker.Worker 1 spark://exp-5-29.ib.cluster:7077
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
starting org.apache.spark.deploy.worker.Worker, logging to /scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-32.out
mySpark: Starting worker on exp-5-33.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark start org.apache.spark.deploy.worker.Worker 1 spark://exp-5-29.ib.cluster:7077
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
starting org.apache.spark.deploy.worker.Worker, logging to /scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-33.out
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2022-02-27 22:40:42,566 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-02-27 22:40:42,819 INFO spark.SparkContext: Running Spark version 3.1.2
2022-02-27 22:40:42,849 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:40:42,850 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-02-27 22:40:42,850 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:40:42,850 INFO spark.SparkContext: Submitted application: add
2022-02-27 22:40:42,866 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 12, script: , vendor: , memory -> name: memory, amount: 24576, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-02-27 22:40:42,888 INFO resource.ResourceProfile: Limiting resource is cpus at 12 tasks per executor
2022-02-27 22:40:42,890 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-02-27 22:40:42,924 INFO spark.SecurityManager: Changing view acls to: txk6771
2022-02-27 22:40:42,924 INFO spark.SecurityManager: Changing modify acls to: txk6771
2022-02-27 22:40:42,924 INFO spark.SecurityManager: Changing view acls groups to: 
2022-02-27 22:40:42,924 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-02-27 22:40:42,924 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(txk6771); groups with view permissions: Set(); users  with modify permissions: Set(txk6771); groups with modify permissions: Set()
2022-02-27 22:40:43,162 INFO util.Utils: Successfully started service 'sparkDriver' on port 36051.
2022-02-27 22:40:43,186 INFO spark.SparkEnv: Registering MapOutputTracker
2022-02-27 22:40:43,210 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-02-27 22:40:43,222 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-02-27 22:40:43,223 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-02-27 22:40:43,226 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-02-27 22:40:43,236 INFO storage.DiskBlockManager: Created local directory at /scratch/txk6771/job_10051764/blockmgr-dcdad0d8-c349-4f19-bdfd-0b889b8406a0
2022-02-27 22:40:43,261 INFO memory.MemoryStore: MemoryStore started with capacity 14.2 GiB
2022-02-27 22:40:43,275 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-02-27 22:40:43,346 INFO util.log: Logging initialized @1873ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-02-27 22:40:43,396 INFO server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 11.0.2+9
2022-02-27 22:40:43,411 INFO server.Server: Started @1939ms
2022-02-27 22:40:43,445 INFO server.AbstractConnector: Started ServerConnector@7f7365da{HTTP/1.1, (http/1.1)}{exp-5-29.ib.cluster:4040}
2022-02-27 22:40:43,445 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-02-27 22:40:43,464 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1e8ab90f{/jobs,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,465 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1229a2b7{/jobs/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,466 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51c959a4{/jobs/job,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,469 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43045f9f{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,469 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6403e24c{/stages,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,470 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4eba373c{/stages/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,470 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d109c4f{/stages/stage,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,472 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70228253{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,473 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@21bd20ee{/stages/pool,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,473 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@421056e5{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,474 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@60bbacfc{/storage,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,474 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@255eaa6b{/storage/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,475 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e7ecd{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,476 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43e9089{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,476 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@352c44a8{/environment,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,477 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a66e580{/environment/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,477 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cdb2d95{/executors,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,478 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2f5ac102{/executors/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,479 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@895416d{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,481 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@80bfdc6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,487 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c6007fb{/static,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,488 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79b84841{/,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,489 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3c87e6b7{/api,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,489 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@25ad4f71{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,490 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f94a5a5{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-27 22:40:43,491 INFO ui.SparkUI: Bound SparkUI to exp-5-29.ib.cluster, and started at http://exp-5-29.ib.cluster:4040
2022-02-27 22:40:43,509 INFO spark.SparkContext: Added JAR file:///home/txk6771/Diablo/diablo/lib/diablo.jar at spark://exp-5-29.ib.cluster:36051/jars/diablo.jar with timestamp 1646030442813
2022-02-27 22:40:43,509 INFO spark.SparkContext: Added JAR file:/home/txk6771/Diablo/diablo/benchmarks/test.jar at spark://exp-5-29.ib.cluster:36051/jars/test.jar with timestamp 1646030442813
2022-02-27 22:40:43,665 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://exp-5-29.ib.cluster:7077...
2022-02-27 22:40:43,712 INFO client.TransportClientFactory: Successfully created connection to exp-5-29.ib.cluster/10.22.5.29:7077 after 25 ms (0 ms spent in bootstraps)
2022-02-27 22:40:43,828 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220227224043-0000
2022-02-27 22:40:43,837 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42265.
2022-02-27 22:40:43,837 INFO netty.NettyBlockTransferService: Server created on exp-5-29.ib.cluster:42265
2022-02-27 22:40:43,838 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-02-27 22:40:43,851 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/0 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,852 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 42265, None)
2022-02-27 22:40:43,854 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/0 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,854 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/1 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,855 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/1 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,855 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/2 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,855 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/2 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,856 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/3 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,858 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/3 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,858 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/4 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,858 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/4 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,859 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/5 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,859 INFO storage.BlockManagerMasterEndpoint: Registering block manager exp-5-29.ib.cluster:42265 with 14.2 GiB RAM, BlockManagerId(driver, exp-5-29.ib.cluster, 42265, None)
2022-02-27 22:40:43,859 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/5 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,860 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/6 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,860 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/6 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,860 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/7 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,860 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/7 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,860 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/8 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,861 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/8 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,861 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/9 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:40:43,862 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 42265, None)
2022-02-27 22:40:43,862 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/9 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,862 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/10 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,862 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/10 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,862 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/11 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,863 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/11 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,863 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, exp-5-29.ib.cluster, 42265, None)
2022-02-27 22:40:43,863 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/12 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,863 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/12 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,864 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/13 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,864 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/13 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,864 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/14 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,864 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/14 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,864 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/15 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,865 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/15 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,865 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/16 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,865 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/16 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,865 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/17 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,865 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/17 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,865 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/18 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,866 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/18 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,866 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/19 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:40:43,866 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/19 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,866 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/20 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,866 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/20 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,866 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/21 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,867 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/21 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,867 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/22 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,867 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/22 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,867 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/23 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,867 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/23 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,867 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/24 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,868 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/24 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,868 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/25 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,868 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/25 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,868 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/26 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,868 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/26 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,868 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/27 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,869 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/27 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,869 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/28 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,869 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/28 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,869 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/29 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:40:43,869 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/29 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,870 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/30 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,870 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/30 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,870 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/31 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,870 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/31 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,870 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/32 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,871 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/32 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,871 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/33 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,871 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/33 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,871 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/34 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,871 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/34 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,871 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/35 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,871 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/35 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,872 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/36 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,872 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/36 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,872 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/37 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,872 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/37 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,872 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/38 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,872 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/38 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,872 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/39 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:40:43,872 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/39 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,873 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/40 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,873 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/40 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,873 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/41 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,873 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/41 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,873 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/42 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,873 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/42 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,873 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/43 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,874 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/43 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,874 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/44 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,874 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/44 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,874 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/45 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,874 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/45 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,874 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/46 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,874 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/46 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,874 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/47 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,874 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/47 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,874 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/48 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,875 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/48 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,875 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224043-0000/49 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:40:43,875 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224043-0000/49 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:40:43,987 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/0 is now RUNNING
2022-02-27 22:40:43,987 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/9 is now RUNNING
2022-02-27 22:40:43,989 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/8 is now RUNNING
2022-02-27 22:40:43,990 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/2 is now RUNNING
2022-02-27 22:40:43,991 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/7 is now RUNNING
2022-02-27 22:40:43,992 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/25 is now RUNNING
2022-02-27 22:40:43,993 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/1 is now RUNNING
2022-02-27 22:40:43,994 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/29 is now RUNNING
2022-02-27 22:40:43,995 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/5 is now RUNNING
2022-02-27 22:40:43,996 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/21 is now RUNNING
2022-02-27 22:40:43,997 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/4 is now RUNNING
2022-02-27 22:40:43,997 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/23 is now RUNNING
2022-02-27 22:40:43,998 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/3 is now RUNNING
2022-02-27 22:40:43,999 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/6 is now RUNNING
2022-02-27 22:40:44,000 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/22 is now RUNNING
2022-02-27 22:40:44,002 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/18 is now RUNNING
2022-02-27 22:40:44,002 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/24 is now RUNNING
2022-02-27 22:40:44,003 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/14 is now RUNNING
2022-02-27 22:40:44,004 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/27 is now RUNNING
2022-02-27 22:40:44,004 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/19 is now RUNNING
2022-02-27 22:40:44,005 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/28 is now RUNNING
2022-02-27 22:40:44,005 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/17 is now RUNNING
2022-02-27 22:40:44,006 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/12 is now RUNNING
2022-02-27 22:40:44,007 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/26 is now RUNNING
2022-02-27 22:40:44,007 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35c4e864{/metrics/json,null,AVAILABLE,@Spark}
2022-02-27 22:40:44,007 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/20 is now RUNNING
2022-02-27 22:40:44,008 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/16 is now RUNNING
2022-02-27 22:40:44,008 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/11 is now RUNNING
2022-02-27 22:40:44,009 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/31 is now RUNNING
2022-02-27 22:40:44,009 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/13 is now RUNNING
2022-02-27 22:40:44,010 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/30 is now RUNNING
2022-02-27 22:40:44,011 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/15 is now RUNNING
2022-02-27 22:40:44,011 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/10 is now RUNNING
2022-02-27 22:40:44,011 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/32 is now RUNNING
2022-02-27 22:40:44,012 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/37 is now RUNNING
2022-02-27 22:40:44,012 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/33 is now RUNNING
2022-02-27 22:40:44,012 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/36 is now RUNNING
2022-02-27 22:40:44,013 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/39 is now RUNNING
2022-02-27 22:40:44,013 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/38 is now RUNNING
2022-02-27 22:40:44,014 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/34 is now RUNNING
2022-02-27 22:40:44,014 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/35 is now RUNNING
2022-02-27 22:40:44,015 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/47 is now RUNNING
2022-02-27 22:40:44,015 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/48 is now RUNNING
2022-02-27 22:40:44,016 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/49 is now RUNNING
2022-02-27 22:40:44,016 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/43 is now RUNNING
2022-02-27 22:40:44,017 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/40 is now RUNNING
2022-02-27 22:40:44,020 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/42 is now RUNNING
2022-02-27 22:40:44,021 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/41 is now RUNNING
2022-02-27 22:40:44,022 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/46 is now RUNNING
2022-02-27 22:40:44,022 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/45 is now RUNNING
2022-02-27 22:40:44,023 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224043-0000/44 is now RUNNING
2022-02-27 22:40:44,047 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2022-02-27 22:40:44,058 WARN spark.SparkContext: Using an existing SparkContext; some configuration may not take effect.
@@@ number of tiles: 10*10 = 100
@@@@ dense matrix size: 0.75 GB
@@@@ sparse matrix size: 114.95 MB
Try: 1/1 time: 2.729
Try: 2/2 time: 2.54
Try: 3/3 time: 2.76
Try: 4/4 time: 2.592
*** MLlib Add dense-dense cores=128 n=10000 m=10000 N=1000 tries=4 2.631 secs
Try: 1/1 time: 13.636
Try: 2/2 time: 12.775
Try: 3/3 time: 12.675
Try: 4/4 time: 12.664
*** MLlib Add sparse-dense cores=128 n=10000 m=10000 N=1000 tries=4 12.705 secs
Try: 1/1 time: 0.535
Try: 2/2 time: 0.236
Try: 3/3 time: 0.301
Try: 4/4 time: 0.169
*** MLlib Add sparse-sparse cores=128 n=10000 m=10000 N=1000 tries=4 0.235 secs
Try: 1/1 time: 2.628
Try: 2/2 time: 1.483
Try: 3/3 time: 1.446
Try: 4/4 time: 1.34
*** DIABLO Add dense-dense giving dense cores=128 n=10000 m=10000 N=1000 tries=4 1.423 secs
Try: 1/1 time: 2.646
Try: 2/2 time: 1.421
Try: 3/3 time: 1.224
Try: 4/4 time: 1.249
*** DIABLO Add sparse-dense giving dense cores=128 n=10000 m=10000 N=1000 tries=4 1.298 secs
Try: 1/1 time: 1.586
Try: 2/2 time: 0.628
Try: 3/3 time: 0.261
Try: 4/4 time: 0.195
*** DIABLO Add sparse-sparse giving dense cores=128 n=10000 m=10000 N=1000 tries=4 0.361 secs
Try: 1/1 time: 2.53
Try: 2/2 time: 1.417
Try: 3/3 time: 1.373
Try: 4/4 time: 1.317
*** DIABLO Add dense-dense giving sparse cores=128 n=10000 m=10000 N=1000 tries=4 1.369 secs
Try: 1/1 time: 1.673
Try: 2/2 time: 1.277
Try: 3/3 time: 1.33
Try: 4/4 time: 1.175
*** DIABLO Add sparse-dense giving sparse cores=128 n=10000 m=10000 N=1000 tries=4 1.261 secs
Try: 1/1 time: 0.727
Try: 2/2 time: 0.614
Try: 3/3 time: 0.335
Try: 4/4 time: 0.206
*** DIABLO Add sparse-sparse giving sparse cores=128 n=10000 m=10000 N=1000 tries=4 0.385 secs
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2022-02-27 22:43:03,842 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-02-27 22:43:04,081 INFO spark.SparkContext: Running Spark version 3.1.2
2022-02-27 22:43:04,109 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:43:04,109 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-02-27 22:43:04,109 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:43:04,110 INFO spark.SparkContext: Submitted application: add
2022-02-27 22:43:04,124 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 12, script: , vendor: , memory -> name: memory, amount: 24576, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-02-27 22:43:04,144 INFO resource.ResourceProfile: Limiting resource is cpus at 12 tasks per executor
2022-02-27 22:43:04,145 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-02-27 22:43:04,179 INFO spark.SecurityManager: Changing view acls to: txk6771
2022-02-27 22:43:04,179 INFO spark.SecurityManager: Changing modify acls to: txk6771
2022-02-27 22:43:04,179 INFO spark.SecurityManager: Changing view acls groups to: 
2022-02-27 22:43:04,179 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-02-27 22:43:04,179 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(txk6771); groups with view permissions: Set(); users  with modify permissions: Set(txk6771); groups with modify permissions: Set()
2022-02-27 22:43:04,413 INFO util.Utils: Successfully started service 'sparkDriver' on port 39853.
2022-02-27 22:43:04,435 INFO spark.SparkEnv: Registering MapOutputTracker
2022-02-27 22:43:04,458 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-02-27 22:43:04,470 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-02-27 22:43:04,470 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-02-27 22:43:04,474 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-02-27 22:43:04,484 INFO storage.DiskBlockManager: Created local directory at /scratch/txk6771/job_10051764/blockmgr-5a52bf74-e00d-4e5c-8744-86dbd1648215
2022-02-27 22:43:04,511 INFO memory.MemoryStore: MemoryStore started with capacity 14.2 GiB
2022-02-27 22:43:04,524 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-02-27 22:43:04,590 INFO util.log: Logging initialized @6700ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-02-27 22:43:04,638 INFO server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 11.0.2+9
2022-02-27 22:43:04,653 INFO server.Server: Started @6763ms
2022-02-27 22:43:04,685 INFO server.AbstractConnector: Started ServerConnector@6c54d94a{HTTP/1.1, (http/1.1)}{exp-5-29.ib.cluster:4040}
2022-02-27 22:43:04,685 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-02-27 22:43:04,704 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1e8ab90f{/jobs,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,705 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1229a2b7{/jobs/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,706 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51c959a4{/jobs/job,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,708 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43045f9f{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,709 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6403e24c{/stages,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,709 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4eba373c{/stages/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,710 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d109c4f{/stages/stage,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,711 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70228253{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,712 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@21bd20ee{/stages/pool,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,713 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@421056e5{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,713 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@60bbacfc{/storage,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,714 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@255eaa6b{/storage/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,715 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e7ecd{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,715 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43e9089{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,716 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@352c44a8{/environment,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,716 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a66e580{/environment/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,717 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cdb2d95{/executors,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,717 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2f5ac102{/executors/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,718 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@895416d{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,722 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@80bfdc6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,729 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c6007fb{/static,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,729 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79b84841{/,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,730 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3c87e6b7{/api,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,731 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@25ad4f71{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,731 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f94a5a5{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-27 22:43:04,733 INFO ui.SparkUI: Bound SparkUI to exp-5-29.ib.cluster, and started at http://exp-5-29.ib.cluster:4040
2022-02-27 22:43:04,749 INFO spark.SparkContext: Added JAR file:///home/txk6771/Diablo/diablo/lib/diablo.jar at spark://exp-5-29.ib.cluster:39853/jars/diablo.jar with timestamp 1646030584076
2022-02-27 22:43:04,749 INFO spark.SparkContext: Added JAR file:/home/txk6771/Diablo/diablo/benchmarks/test.jar at spark://exp-5-29.ib.cluster:39853/jars/test.jar with timestamp 1646030584076
2022-02-27 22:43:04,897 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://exp-5-29.ib.cluster:7077...
2022-02-27 22:43:04,941 INFO client.TransportClientFactory: Successfully created connection to exp-5-29.ib.cluster/10.22.5.29:7077 after 24 ms (0 ms spent in bootstraps)
2022-02-27 22:43:05,029 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220227224305-0001
2022-02-27 22:43:05,032 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/0 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,034 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/0 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,035 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/1 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,036 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/1 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,036 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/2 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,036 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/2 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,036 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/3 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,037 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/3 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,037 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/4 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,039 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/4 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,039 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/5 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,039 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33751.
2022-02-27 22:43:05,039 INFO netty.NettyBlockTransferService: Server created on exp-5-29.ib.cluster:33751
2022-02-27 22:43:05,039 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/5 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,039 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/6 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,040 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/6 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,040 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/7 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,040 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/7 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,040 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/8 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,040 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/8 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,040 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-02-27 22:43:05,041 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/9 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:43:05,041 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/9 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,041 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/10 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,041 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/10 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,041 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/11 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,042 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/11 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,042 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/12 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,042 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/12 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,042 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/13 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,042 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/13 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,042 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/14 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,043 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/14 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,043 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/15 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,043 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/15 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,043 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/16 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,043 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/16 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,044 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/17 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,044 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/17 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,044 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/18 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,044 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/18 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,044 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/19 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:43:05,045 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/19 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,045 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/20 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,045 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/20 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,045 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/21 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,045 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/21 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,046 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/22 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,046 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/22 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,046 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/23 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,046 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/23 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,046 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 33751, None)
2022-02-27 22:43:05,046 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/24 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,046 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/24 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,047 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/25 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,047 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/25 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,047 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/26 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,047 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/26 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,047 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/27 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,048 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/27 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,048 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/28 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,048 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/28 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,048 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/29 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:43:05,049 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/29 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,049 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/30 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,049 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/30 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,049 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/31 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,049 INFO storage.BlockManagerMasterEndpoint: Registering block manager exp-5-29.ib.cluster:33751 with 14.2 GiB RAM, BlockManagerId(driver, exp-5-29.ib.cluster, 33751, None)
2022-02-27 22:43:05,050 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/31 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,050 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/32 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,050 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/32 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,050 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/33 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,050 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/33 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,051 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/34 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,051 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/34 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,051 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/35 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,051 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/35 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,051 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/36 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,052 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/36 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,052 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/37 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,052 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 33751, None)
2022-02-27 22:43:05,052 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/37 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,052 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/38 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,052 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/38 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,052 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/39 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:43:05,052 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/39 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,052 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/40 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,053 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, exp-5-29.ib.cluster, 33751, None)
2022-02-27 22:43:05,053 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/40 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,053 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/41 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,053 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/41 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,053 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/42 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,053 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/42 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,053 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/43 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,054 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/43 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,054 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/44 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,054 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/44 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,054 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/45 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,054 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/45 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,054 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/46 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,054 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/46 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,054 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/47 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,054 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/47 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,054 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/48 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,055 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/48 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,055 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224305-0001/49 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:43:05,055 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224305-0001/49 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:43:05,058 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/21 is now RUNNING
2022-02-27 22:43:05,059 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/20 is now RUNNING
2022-02-27 22:43:05,060 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/1 is now RUNNING
2022-02-27 22:43:05,062 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/0 is now RUNNING
2022-02-27 22:43:05,063 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/2 is now RUNNING
2022-02-27 22:43:05,064 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/4 is now RUNNING
2022-02-27 22:43:05,065 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/11 is now RUNNING
2022-02-27 22:43:05,066 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/31 is now RUNNING
2022-02-27 22:43:05,067 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/13 is now RUNNING
2022-02-27 22:43:05,067 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/30 is now RUNNING
2022-02-27 22:43:05,068 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/34 is now RUNNING
2022-02-27 22:43:05,069 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/32 is now RUNNING
2022-02-27 22:43:05,069 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/33 is now RUNNING
2022-02-27 22:43:05,070 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/35 is now RUNNING
2022-02-27 22:43:05,071 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/36 is now RUNNING
2022-02-27 22:43:05,072 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/5 is now RUNNING
2022-02-27 22:43:05,073 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/3 is now RUNNING
2022-02-27 22:43:05,074 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/22 is now RUNNING
2022-02-27 22:43:05,074 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/23 is now RUNNING
2022-02-27 22:43:05,075 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/25 is now RUNNING
2022-02-27 22:43:05,075 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/10 is now RUNNING
2022-02-27 22:43:05,076 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/37 is now RUNNING
2022-02-27 22:43:05,076 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/7 is now RUNNING
2022-02-27 22:43:05,077 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/38 is now RUNNING
2022-02-27 22:43:05,077 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/39 is now RUNNING
2022-02-27 22:43:05,078 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/12 is now RUNNING
2022-02-27 22:43:05,078 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/24 is now RUNNING
2022-02-27 22:43:05,079 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/15 is now RUNNING
2022-02-27 22:43:05,079 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/26 is now RUNNING
2022-02-27 22:43:05,079 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/8 is now RUNNING
2022-02-27 22:43:05,080 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/9 is now RUNNING
2022-02-27 22:43:05,080 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/14 is now RUNNING
2022-02-27 22:43:05,080 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/6 is now RUNNING
2022-02-27 22:43:05,081 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/17 is now RUNNING
2022-02-27 22:43:05,081 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/19 is now RUNNING
2022-02-27 22:43:05,082 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/16 is now RUNNING
2022-02-27 22:43:05,082 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/18 is now RUNNING
2022-02-27 22:43:05,083 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/28 is now RUNNING
2022-02-27 22:43:05,083 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/27 is now RUNNING
2022-02-27 22:43:05,083 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/29 is now RUNNING
2022-02-27 22:43:05,084 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/41 is now RUNNING
2022-02-27 22:43:05,084 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/44 is now RUNNING
2022-02-27 22:43:05,084 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/46 is now RUNNING
2022-02-27 22:43:05,085 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/45 is now RUNNING
2022-02-27 22:43:05,085 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/40 is now RUNNING
2022-02-27 22:43:05,085 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/48 is now RUNNING
2022-02-27 22:43:05,089 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/42 is now RUNNING
2022-02-27 22:43:05,089 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/47 is now RUNNING
2022-02-27 22:43:05,089 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/43 is now RUNNING
2022-02-27 22:43:05,090 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224305-0001/49 is now RUNNING
2022-02-27 22:43:05,193 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@32a2a6be{/metrics/json,null,AVAILABLE,@Spark}
2022-02-27 22:43:05,228 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2022-02-27 22:43:05,238 WARN spark.SparkContext: Using an existing SparkContext; some configuration may not take effect.
@@@ number of tiles: 20*20 = 400
@@@@ dense matrix size: 2.98 GB
@@@@ sparse matrix size: 461.00 MB
Try: 1/1 time: 9.793
Try: 2/2 time: 9.348
Try: 3/3 time: 9.149
Try: 4/4 time: 9.365
*** MLlib Add dense-dense cores=128 n=20000 m=20000 N=1000 tries=4 9.287 secs
Try: 1/1 time: 16.818
Try: 2/2 time: 16.225
Try: 3/3 time: 16.018
Try: 4/4 time: 16.209
*** MLlib Add sparse-dense cores=128 n=20000 m=20000 N=1000 tries=4 16.151 secs
Try: 1/1 time: 0.806
Try: 2/2 time: 0.509
Try: 3/3 time: 0.22
Try: 4/4 time: 0.281
*** MLlib Add sparse-sparse cores=128 n=20000 m=20000 N=1000 tries=4 0.337 secs
Try: 1/1 time: 7.368
Try: 2/2 time: 5.33
Try: 3/3 time: 5.227
Try: 4/4 time: 5.244
*** DIABLO Add dense-dense giving dense cores=128 n=20000 m=20000 N=1000 tries=4 5.267 secs
Try: 1/1 time: 5.367
Try: 2/2 time: 3.771
Try: 3/3 time: 3.792
Try: 4/4 time: 3.934
*** DIABLO Add sparse-dense giving dense cores=128 n=20000 m=20000 N=1000 tries=4 3.832 secs
Try: 1/1 time: 2.113
Try: 2/2 time: 0.406
Try: 3/3 time: 0.325
Try: 4/4 time: 0.346
*** DIABLO Add sparse-sparse giving dense cores=128 n=20000 m=20000 N=1000 tries=4 0.359 secs
Try: 1/1 time: 5.543
Try: 2/2 time: 5.148
Try: 3/3 time: 4.877
Try: 4/4 time: 5.043
*** DIABLO Add dense-dense giving sparse cores=128 n=20000 m=20000 N=1000 tries=4 5.023 secs
Try: 1/1 time: 4.279
Try: 2/2 time: 3.897
Try: 3/3 time: 3.839
Try: 4/4 time: 3.897
*** DIABLO Add sparse-dense giving sparse cores=128 n=20000 m=20000 N=1000 tries=4 3.878 secs
Try: 1/1 time: 1.609
Try: 2/2 time: 0.414
Try: 3/3 time: 0.495
Try: 4/4 time: 0.428
*** DIABLO Add sparse-sparse giving sparse cores=128 n=20000 m=20000 N=1000 tries=4 0.446 secs
2022-02-27 22:47:23,061 ERROR client.TransportResponseHandler: Still have 2 requests outstanding when connection from /10.22.5.32:47688 is closed
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@75b00870 rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-02-27 22:47:23,061 ERROR client.TransportResponseHandler: Still have 7 requests outstanding when connection from /10.22.5.31:54950 is closed
2022-02-27 22:47:23,062 ERROR client.TransportResponseHandler: Still have 4 requests outstanding when connection from /10.22.5.32:47696 is closed
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@345f2f58 rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@65d45a2e rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@6d9a5cce rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@2e083d7b rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@43704296 rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@5cbd7247 rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@20971d1d rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@4181a82 rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@159725fe rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@30697a56 rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@5dc6ac1f rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@79fa78ce rejected from java.util.concurrent.ThreadPoolExecutor@5c3c99f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 17339]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:117)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:428)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:377)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:763)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:525)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2022-02-27 22:47:24,528 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-02-27 22:47:24,766 INFO spark.SparkContext: Running Spark version 3.1.2
2022-02-27 22:47:24,792 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:47:24,792 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-02-27 22:47:24,792 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:47:24,793 INFO spark.SparkContext: Submitted application: add
2022-02-27 22:47:24,808 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 12, script: , vendor: , memory -> name: memory, amount: 24576, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-02-27 22:47:24,824 INFO resource.ResourceProfile: Limiting resource is cpus at 12 tasks per executor
2022-02-27 22:47:24,826 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-02-27 22:47:24,858 INFO spark.SecurityManager: Changing view acls to: txk6771
2022-02-27 22:47:24,858 INFO spark.SecurityManager: Changing modify acls to: txk6771
2022-02-27 22:47:24,858 INFO spark.SecurityManager: Changing view acls groups to: 
2022-02-27 22:47:24,858 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-02-27 22:47:24,858 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(txk6771); groups with view permissions: Set(); users  with modify permissions: Set(txk6771); groups with modify permissions: Set()
2022-02-27 22:47:25,091 INFO util.Utils: Successfully started service 'sparkDriver' on port 40697.
2022-02-27 22:47:25,114 INFO spark.SparkEnv: Registering MapOutputTracker
2022-02-27 22:47:25,140 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-02-27 22:47:25,152 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-02-27 22:47:25,153 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-02-27 22:47:25,156 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-02-27 22:47:25,166 INFO storage.DiskBlockManager: Created local directory at /scratch/txk6771/job_10051764/blockmgr-cd66b72e-d278-4bdc-88a5-452506352ad4
2022-02-27 22:47:25,192 INFO memory.MemoryStore: MemoryStore started with capacity 14.2 GiB
2022-02-27 22:47:25,205 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-02-27 22:47:25,274 INFO util.log: Logging initialized @1874ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-02-27 22:47:25,325 INFO server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 11.0.2+9
2022-02-27 22:47:25,341 INFO server.Server: Started @1942ms
2022-02-27 22:47:25,379 INFO server.AbstractConnector: Started ServerConnector@7f7365da{HTTP/1.1, (http/1.1)}{exp-5-29.ib.cluster:4040}
2022-02-27 22:47:25,379 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-02-27 22:47:25,399 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f7076bc{/jobs,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,401 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b6860f9{/jobs/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,402 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@31ee2fdb{/jobs/job,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,404 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@767a014e{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,405 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3968bc60{/stages,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,405 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@227a47{/stages/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,406 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@75ae4a1f{/stages/stage,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,408 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2849434b{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,408 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65b97f47{/stages/pool,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,409 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@476fe690{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,410 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54e3658c{/storage,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,410 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3c5dbdf8{/storage/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,411 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7aac8884{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,411 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5b852b49{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,412 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@122d6c22{/environment,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,413 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5df778c3{/environment/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,413 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71a06021{/executors,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,414 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6edcad64{/executors/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,414 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3e33d73e{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,418 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@623dcf2a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,425 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@e84fb85{/static,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,425 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7ceb4478{/,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,426 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@25ad4f71{/api,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,427 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1422ac7f{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,427 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7bc44ce8{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,429 INFO ui.SparkUI: Bound SparkUI to exp-5-29.ib.cluster, and started at http://exp-5-29.ib.cluster:4040
2022-02-27 22:47:25,446 INFO spark.SparkContext: Added JAR file:///home/txk6771/Diablo/diablo/lib/diablo.jar at spark://exp-5-29.ib.cluster:40697/jars/diablo.jar with timestamp 1646030844760
2022-02-27 22:47:25,446 INFO spark.SparkContext: Added JAR file:/home/txk6771/Diablo/diablo/benchmarks/test.jar at spark://exp-5-29.ib.cluster:40697/jars/test.jar with timestamp 1646030844760
2022-02-27 22:47:25,610 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://exp-5-29.ib.cluster:7077...
2022-02-27 22:47:25,657 INFO client.TransportClientFactory: Successfully created connection to exp-5-29.ib.cluster/10.22.5.29:7077 after 27 ms (0 ms spent in bootstraps)
2022-02-27 22:47:25,748 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220227224725-0002
2022-02-27 22:47:25,752 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/0 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,755 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/0 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,756 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/1 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,757 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/1 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,757 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/2 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,757 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/2 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,757 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/3 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,758 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/3 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,758 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/4 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,758 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/4 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,758 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/5 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,758 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/5 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,759 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/6 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,759 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/6 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,759 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/7 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,759 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/7 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,759 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/8 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,760 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/8 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,760 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/9 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:47:25,760 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/9 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,760 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/10 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,760 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/10 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,760 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/11 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,761 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/11 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,761 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/12 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,763 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/12 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,763 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/13 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,763 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43337.
2022-02-27 22:47:25,763 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/13 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,763 INFO netty.NettyBlockTransferService: Server created on exp-5-29.ib.cluster:43337
2022-02-27 22:47:25,764 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/14 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,764 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/14 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,764 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/15 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,764 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/15 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,764 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/16 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,765 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/16 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,765 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/17 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,765 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/17 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,765 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/18 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,766 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-02-27 22:47:25,766 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/18 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,766 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/19 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:47:25,766 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/19 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,766 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/20 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,766 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/20 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,766 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/21 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,767 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/21 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,767 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/22 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,767 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/22 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,767 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/23 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,767 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/23 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,767 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/24 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,768 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/24 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,768 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/25 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,768 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/25 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,768 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/26 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,768 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/26 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,768 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/27 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,769 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/27 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,769 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/28 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,769 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/28 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,769 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/29 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:47:25,769 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/29 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,769 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/30 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,770 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/30 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,770 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/31 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,770 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/31 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,770 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/32 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,770 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/32 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,771 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/33 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,771 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/33 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,771 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/34 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,771 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/34 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,771 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/35 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,772 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/35 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,772 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/36 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,772 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/36 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,772 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/37 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,772 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/37 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,772 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/38 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,772 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/38 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,773 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/39 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:47:25,773 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/39 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,773 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 43337, None)
2022-02-27 22:47:25,773 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/40 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,773 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/40 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,773 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/41 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,773 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/41 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,774 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/42 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,774 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/42 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,774 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/43 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,774 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/43 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,774 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/44 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,774 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/44 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,775 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/45 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,775 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/45 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,775 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/46 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,775 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/46 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,775 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/47 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,775 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/47 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,775 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/48 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,775 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/48 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,776 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227224725-0002/49 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:47:25,776 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227224725-0002/49 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:47:25,778 INFO storage.BlockManagerMasterEndpoint: Registering block manager exp-5-29.ib.cluster:43337 with 14.2 GiB RAM, BlockManagerId(driver, exp-5-29.ib.cluster, 43337, None)
2022-02-27 22:47:25,781 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 43337, None)
2022-02-27 22:47:25,782 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, exp-5-29.ib.cluster, 43337, None)
2022-02-27 22:47:25,783 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/21 is now RUNNING
2022-02-27 22:47:25,783 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/20 is now RUNNING
2022-02-27 22:47:25,785 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/25 is now RUNNING
2022-02-27 22:47:25,785 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/24 is now RUNNING
2022-02-27 22:47:25,786 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/22 is now RUNNING
2022-02-27 22:47:25,787 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/26 is now RUNNING
2022-02-27 22:47:25,788 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/23 is now RUNNING
2022-02-27 22:47:25,789 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/0 is now RUNNING
2022-02-27 22:47:25,790 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/1 is now RUNNING
2022-02-27 22:47:25,791 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/5 is now RUNNING
2022-02-27 22:47:25,792 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/28 is now RUNNING
2022-02-27 22:47:25,793 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/4 is now RUNNING
2022-02-27 22:47:25,794 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/29 is now RUNNING
2022-02-27 22:47:25,795 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/27 is now RUNNING
2022-02-27 22:47:25,795 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/2 is now RUNNING
2022-02-27 22:47:25,797 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/3 is now RUNNING
2022-02-27 22:47:25,798 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/11 is now RUNNING
2022-02-27 22:47:25,798 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/10 is now RUNNING
2022-02-27 22:47:25,799 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/6 is now RUNNING
2022-02-27 22:47:25,799 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/12 is now RUNNING
2022-02-27 22:47:25,800 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/7 is now RUNNING
2022-02-27 22:47:25,801 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/14 is now RUNNING
2022-02-27 22:47:25,801 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/9 is now RUNNING
2022-02-27 22:47:25,802 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/34 is now RUNNING
2022-02-27 22:47:25,802 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/8 is now RUNNING
2022-02-27 22:47:25,803 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/31 is now RUNNING
2022-02-27 22:47:25,803 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/30 is now RUNNING
2022-02-27 22:47:25,804 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/13 is now RUNNING
2022-02-27 22:47:25,804 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/32 is now RUNNING
2022-02-27 22:47:25,805 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/16 is now RUNNING
2022-02-27 22:47:25,805 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/15 is now RUNNING
2022-02-27 22:47:25,806 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/18 is now RUNNING
2022-02-27 22:47:25,806 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/17 is now RUNNING
2022-02-27 22:47:25,807 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/19 is now RUNNING
2022-02-27 22:47:25,807 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/33 is now RUNNING
2022-02-27 22:47:25,808 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/36 is now RUNNING
2022-02-27 22:47:25,808 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/35 is now RUNNING
2022-02-27 22:47:25,808 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/44 is now RUNNING
2022-02-27 22:47:25,809 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/37 is now RUNNING
2022-02-27 22:47:25,809 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/41 is now RUNNING
2022-02-27 22:47:25,809 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/39 is now RUNNING
2022-02-27 22:47:25,810 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/42 is now RUNNING
2022-02-27 22:47:25,810 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/48 is now RUNNING
2022-02-27 22:47:25,811 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/45 is now RUNNING
2022-02-27 22:47:25,811 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/43 is now RUNNING
2022-02-27 22:47:25,811 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/38 is now RUNNING
2022-02-27 22:47:25,811 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/49 is now RUNNING
2022-02-27 22:47:25,812 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/40 is now RUNNING
2022-02-27 22:47:25,812 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/47 is now RUNNING
2022-02-27 22:47:25,812 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227224725-0002/46 is now RUNNING
2022-02-27 22:47:25,926 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5584d9c6{/metrics/json,null,AVAILABLE,@Spark}
2022-02-27 22:47:25,962 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2022-02-27 22:47:25,973 WARN spark.SparkContext: Using an existing SparkContext; some configuration may not take effect.
@@@ number of tiles: 30*30 = 900
@@@@ dense matrix size: 6.71 GB
@@@@ sparse matrix size: 1034.82 MB
Try: 1/1 time: 21.501
Try: 2/2 time: 20.704
Try: 3/3 time: 20.902
Try: 4/4 time: 18.117
*** MLlib Add dense-dense cores=128 n=30000 m=30000 N=1000 tries=4 19.908 secs
Try: 1/1 time: 35.535
Try: 2/2 time: 34.796
Try: 3/3 time: 34.731
Try: 4/4 time: 34.869
*** MLlib Add sparse-dense cores=128 n=30000 m=30000 N=1000 tries=4 34.799 secs
Try: 1/1 time: 1.1
Try: 2/2 time: 0.7
Try: 3/3 time: 0.347
Try: 4/4 time: 0.266
*** MLlib Add sparse-sparse cores=128 n=30000 m=30000 N=1000 tries=4 0.438 secs
Try: 1/1 time: 16.211
Try: 2/2 time: 12.683
Try: 3/3 time: 14.527
Try: 4/4 time: 14.245
*** DIABLO Add dense-dense giving dense cores=128 n=30000 m=30000 N=1000 tries=4 13.818 secs
Try: 1/1 time: 11.055
Try: 2/2 time: 8.222
Try: 3/3 time: 8.43
Try: 4/4 time: 8.181
*** DIABLO Add sparse-dense giving dense cores=128 n=30000 m=30000 N=1000 tries=4 8.278 secs
Try: 1/1 time: 3.854
Try: 2/2 time: 0.718
Try: 3/3 time: 0.665
Try: 4/4 time: 0.846
*** DIABLO Add sparse-sparse giving dense cores=128 n=30000 m=30000 N=1000 tries=4 0.743 secs
Try: 1/1 time: 12.347
Try: 2/2 time: 13.389
Try: 3/3 time: 13.366
Try: 4/4 time: 14.856
*** DIABLO Add dense-dense giving sparse cores=128 n=30000 m=30000 N=1000 tries=4 13.870 secs
Try: 1/1 time: 9.536
Try: 2/2 time: 8.582
Try: 3/3 time: 8.521
Try: 4/4 time: 8.38
*** DIABLO Add sparse-dense giving sparse cores=128 n=30000 m=30000 N=1000 tries=4 8.494 secs
Try: 1/1 time: 1.414
Try: 2/2 time: 0.708
Try: 3/3 time: 0.808
Try: 4/4 time: 0.927
*** DIABLO Add sparse-sparse giving sparse cores=128 n=30000 m=30000 N=1000 tries=4 0.814 secs
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2022-02-27 22:56:28,085 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-02-27 22:56:28,317 INFO spark.SparkContext: Running Spark version 3.1.2
2022-02-27 22:56:28,342 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:56:28,342 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-02-27 22:56:28,343 INFO resource.ResourceUtils: ==============================================================
2022-02-27 22:56:28,343 INFO spark.SparkContext: Submitted application: add
2022-02-27 22:56:28,357 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 12, script: , vendor: , memory -> name: memory, amount: 24576, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-02-27 22:56:28,373 INFO resource.ResourceProfile: Limiting resource is cpus at 12 tasks per executor
2022-02-27 22:56:28,375 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-02-27 22:56:28,406 INFO spark.SecurityManager: Changing view acls to: txk6771
2022-02-27 22:56:28,406 INFO spark.SecurityManager: Changing modify acls to: txk6771
2022-02-27 22:56:28,406 INFO spark.SecurityManager: Changing view acls groups to: 
2022-02-27 22:56:28,406 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-02-27 22:56:28,406 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(txk6771); groups with view permissions: Set(); users  with modify permissions: Set(txk6771); groups with modify permissions: Set()
2022-02-27 22:56:28,615 INFO util.Utils: Successfully started service 'sparkDriver' on port 42735.
2022-02-27 22:56:28,636 INFO spark.SparkEnv: Registering MapOutputTracker
2022-02-27 22:56:28,658 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-02-27 22:56:28,670 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-02-27 22:56:28,671 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-02-27 22:56:28,674 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-02-27 22:56:28,684 INFO storage.DiskBlockManager: Created local directory at /scratch/txk6771/job_10051764/blockmgr-68813fc8-cce0-4fda-8e21-32fea8c1f942
2022-02-27 22:56:28,705 INFO memory.MemoryStore: MemoryStore started with capacity 14.2 GiB
2022-02-27 22:56:28,735 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-02-27 22:56:28,803 INFO util.log: Logging initialized @1827ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-02-27 22:56:28,850 INFO server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 11.0.2+9
2022-02-27 22:56:28,865 INFO server.Server: Started @1890ms
2022-02-27 22:56:28,902 INFO server.AbstractConnector: Started ServerConnector@2ac969c0{HTTP/1.1, (http/1.1)}{exp-5-29.ib.cluster:4040}
2022-02-27 22:56:28,903 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-02-27 22:56:28,922 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a729f84{/jobs,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,924 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51c959a4{/jobs/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,924 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10a0fe30{/jobs/job,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,927 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6403e24c{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,928 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4eba373c{/stages,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,928 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d109c4f{/stages/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,929 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26f46fa6{/stages/stage,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,930 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@21bd20ee{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,931 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@421056e5{/stages/pool,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,932 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@60bbacfc{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,932 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@255eaa6b{/storage,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,933 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e7ecd{/storage/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,933 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43e9089{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,934 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@352c44a8{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,935 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a66e580{/environment,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,935 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cdb2d95{/environment/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,936 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2f5ac102{/executors,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,936 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@895416d{/executors/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,937 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@80bfdc6{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,940 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c6007fb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,948 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6981f8f3{/static,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,948 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3c87e6b7{/,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,949 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3c3a0032{/api,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,950 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f94a5a5{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,951 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a451491{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-27 22:56:28,952 INFO ui.SparkUI: Bound SparkUI to exp-5-29.ib.cluster, and started at http://exp-5-29.ib.cluster:4040
2022-02-27 22:56:28,969 INFO spark.SparkContext: Added JAR file:///home/txk6771/Diablo/diablo/lib/diablo.jar at spark://exp-5-29.ib.cluster:42735/jars/diablo.jar with timestamp 1646031388311
2022-02-27 22:56:28,969 INFO spark.SparkContext: Added JAR file:/home/txk6771/Diablo/diablo/benchmarks/test.jar at spark://exp-5-29.ib.cluster:42735/jars/test.jar with timestamp 1646031388311
2022-02-27 22:56:29,117 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://exp-5-29.ib.cluster:7077...
2022-02-27 22:56:29,161 INFO client.TransportClientFactory: Successfully created connection to exp-5-29.ib.cluster/10.22.5.29:7077 after 25 ms (0 ms spent in bootstraps)
2022-02-27 22:56:29,243 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220227225629-0003
2022-02-27 22:56:29,244 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/0 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,247 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/0 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,247 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/1 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,248 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/1 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,248 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/2 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,248 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/2 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,248 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/3 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,252 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/3 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,252 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39607.
2022-02-27 22:56:29,252 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/4 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,252 INFO netty.NettyBlockTransferService: Server created on exp-5-29.ib.cluster:39607
2022-02-27 22:56:29,253 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/4 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,253 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/5 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,253 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/5 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,253 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/6 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,253 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/6 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,254 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/7 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,254 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-02-27 22:56:29,254 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/7 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,254 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/8 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,254 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/8 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,254 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/9 on worker-20220227224032-10.22.5.31-33079 (10.22.5.31:33079) with 12 core(s)
2022-02-27 22:56:29,255 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/9 on hostPort 10.22.5.31:33079 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,255 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/10 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,255 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/10 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,255 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/11 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,256 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/11 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,256 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/12 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,256 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/12 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,256 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/13 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,256 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/13 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,257 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/14 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,257 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/14 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,257 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/15 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,257 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/15 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,257 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/16 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,258 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/16 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,258 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/17 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,258 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/17 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,258 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/18 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,259 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/18 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,259 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/19 on worker-20220227224028-10.22.5.30-44425 (10.22.5.30:44425) with 12 core(s)
2022-02-27 22:56:29,259 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/19 on hostPort 10.22.5.30:44425 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,259 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/20 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,259 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/20 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,259 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/21 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,260 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/21 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,260 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/22 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,260 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/22 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,260 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 39607, None)
2022-02-27 22:56:29,260 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/23 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,260 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/23 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,260 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/24 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,261 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/24 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,261 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/25 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,261 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/25 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,261 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/26 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,261 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/26 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,261 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/27 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,262 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/27 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,262 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/28 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,262 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/28 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,263 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/29 on worker-20220227224036-10.22.5.32-36829 (10.22.5.32:36829) with 12 core(s)
2022-02-27 22:56:29,263 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/29 on hostPort 10.22.5.32:36829 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,263 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/30 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,263 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/30 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,263 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/31 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,263 INFO storage.BlockManagerMasterEndpoint: Registering block manager exp-5-29.ib.cluster:39607 with 14.2 GiB RAM, BlockManagerId(driver, exp-5-29.ib.cluster, 39607, None)
2022-02-27 22:56:29,264 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/31 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,264 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/32 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,265 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/32 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,265 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/33 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,265 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/33 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,265 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/34 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,265 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/34 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,266 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/35 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,267 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/35 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,267 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/36 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,267 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, exp-5-29.ib.cluster, 39607, None)
2022-02-27 22:56:29,267 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/36 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,267 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/37 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,267 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/37 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,267 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/38 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,267 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/38 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,267 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/39 on worker-20220227224024-10.22.5.29-39941 (10.22.5.29:39941) with 12 core(s)
2022-02-27 22:56:29,267 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, exp-5-29.ib.cluster, 39607, None)
2022-02-27 22:56:29,268 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/39 on hostPort 10.22.5.29:39941 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,268 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/40 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,268 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/40 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,268 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/41 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,268 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/41 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,268 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/42 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,268 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/42 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,269 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/43 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,269 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/43 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,269 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/44 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,269 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/44 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,269 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/45 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,269 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/45 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,269 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/46 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,269 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/46 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,269 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/47 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,270 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/47 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,270 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/48 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,270 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/48 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,270 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220227225629-0003/49 on worker-20220227224040-10.22.5.33-36271 (10.22.5.33:36271) with 12 core(s)
2022-02-27 22:56:29,270 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220227225629-0003/49 on hostPort 10.22.5.33:36271 with 12 core(s), 24.0 GiB RAM
2022-02-27 22:56:29,274 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/14 is now RUNNING
2022-02-27 22:56:29,274 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/15 is now RUNNING
2022-02-27 22:56:29,277 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/12 is now RUNNING
2022-02-27 22:56:29,278 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/30 is now RUNNING
2022-02-27 22:56:29,279 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/10 is now RUNNING
2022-02-27 22:56:29,280 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/48 is now RUNNING
2022-02-27 22:56:29,281 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/20 is now RUNNING
2022-02-27 22:56:29,282 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/34 is now RUNNING
2022-02-27 22:56:29,283 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/47 is now RUNNING
2022-02-27 22:56:29,284 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/25 is now RUNNING
2022-02-27 22:56:29,285 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/37 is now RUNNING
2022-02-27 22:56:29,286 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/21 is now RUNNING
2022-02-27 22:56:29,286 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/24 is now RUNNING
2022-02-27 22:56:29,287 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/22 is now RUNNING
2022-02-27 22:56:29,288 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/33 is now RUNNING
2022-02-27 22:56:29,290 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/29 is now RUNNING
2022-02-27 22:56:29,290 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/28 is now RUNNING
2022-02-27 22:56:29,291 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/39 is now RUNNING
2022-02-27 22:56:29,292 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/40 is now RUNNING
2022-02-27 22:56:29,292 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/17 is now RUNNING
2022-02-27 22:56:29,293 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/11 is now RUNNING
2022-02-27 22:56:29,293 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/35 is now RUNNING
2022-02-27 22:56:29,294 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/36 is now RUNNING
2022-02-27 22:56:29,294 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/32 is now RUNNING
2022-02-27 22:56:29,295 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/31 is now RUNNING
2022-02-27 22:56:29,295 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/13 is now RUNNING
2022-02-27 22:56:29,296 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/38 is now RUNNING
2022-02-27 22:56:29,296 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/16 is now RUNNING
2022-02-27 22:56:29,297 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/45 is now RUNNING
2022-02-27 22:56:29,297 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/18 is now RUNNING
2022-02-27 22:56:29,298 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/19 is now RUNNING
2022-02-27 22:56:29,298 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/26 is now RUNNING
2022-02-27 22:56:29,299 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/23 is now RUNNING
2022-02-27 22:56:29,299 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/27 is now RUNNING
2022-02-27 22:56:29,299 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/0 is now RUNNING
2022-02-27 22:56:29,300 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/46 is now RUNNING
2022-02-27 22:56:29,300 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/43 is now RUNNING
2022-02-27 22:56:29,301 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/4 is now RUNNING
2022-02-27 22:56:29,301 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/5 is now RUNNING
2022-02-27 22:56:29,301 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/1 is now RUNNING
2022-02-27 22:56:29,302 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/2 is now RUNNING
2022-02-27 22:56:29,302 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/6 is now RUNNING
2022-02-27 22:56:29,302 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/9 is now RUNNING
2022-02-27 22:56:29,302 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/41 is now RUNNING
2022-02-27 22:56:29,303 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/44 is now RUNNING
2022-02-27 22:56:29,303 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/42 is now RUNNING
2022-02-27 22:56:29,303 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/49 is now RUNNING
2022-02-27 22:56:29,304 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/3 is now RUNNING
2022-02-27 22:56:29,304 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/7 is now RUNNING
2022-02-27 22:56:29,304 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220227225629-0003/8 is now RUNNING
2022-02-27 22:56:29,400 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f36c8e3{/metrics/json,null,AVAILABLE,@Spark}
2022-02-27 22:56:29,439 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2022-02-27 22:56:29,450 WARN spark.SparkContext: Using an existing SparkContext; some configuration may not take effect.
@@@ number of tiles: 40*40 = 1600
@@@@ dense matrix size: 11.92 GB
@@@@ sparse matrix size: 1828.14 MB
Try: 1/1 time: 38.255
Try: 2/2 time: 41.842
Try: 3/3 time: 46.946
Try: 4/4 time: 37.83
*** MLlib Add dense-dense cores=128 n=40000 m=40000 N=1000 tries=4 42.206 secs
Try: 1/1 time: 81.56
Try: 2/2 time: 63.681
Try: 3/3 time: 63.772
Try: 4/4 time: 63.323
*** MLlib Add sparse-dense cores=128 n=40000 m=40000 N=1000 tries=4 63.592 secs
Try: 1/1 time: 11.193
Try: 2/2 time: 0.338
Try: 3/3 time: 0.37
Try: 4/4 time: 0.382
*** MLlib Add sparse-sparse cores=128 n=40000 m=40000 N=1000 tries=4 0.363 secs
Try: 1/1 time: 27.163
Try: 2/2 time: 17.828
Try: 3/3 time: 19.1
Try: 4/4 time: 19.245
*** DIABLO Add dense-dense giving dense cores=128 n=40000 m=40000 N=1000 tries=4 18.724 secs
Try: 1/1 time: 19.682
Try: 2/2 time: 15.832
Try: 3/3 time: 15.175
Try: 4/4 time: 15.511
*** DIABLO Add sparse-dense giving dense cores=128 n=40000 m=40000 N=1000 tries=4 15.506 secs
Try: 1/1 time: 6.396
Try: 2/2 time: 1.246
Try: 3/3 time: 1.261
Try: 4/4 time: 1.407
*** DIABLO Add sparse-sparse giving dense cores=128 n=40000 m=40000 N=1000 tries=4 1.305 secs
Try: 1/1 time: 20.208
Try: 2/2 time: 19.594
Try: 3/3 time: 19.385
Try: 4/4 time: 21.363
*** DIABLO Add dense-dense giving sparse cores=128 n=40000 m=40000 N=1000 tries=4 20.114 secs
Try: 1/1 time: 17.388
Try: 2/2 time: 16.082
Try: 3/3 time: 16.454
Try: 4/4 time: 15.888
*** DIABLO Add sparse-dense giving sparse cores=128 n=40000 m=40000 N=1000 tries=4 16.141 secs
Try: 1/1 time: 2.032
Try: 2/2 time: 1.511
Try: 3/3 time: 1.659
Try: 4/4 time: 1.505
*** DIABLO Add sparse-sparse giving sparse cores=128 n=40000 m=40000 N=1000 tries=4 1.558 secs
mySpark: Using /home/txk6771/expansecluster/spark/slaves as our slaves file
mySpark: Reading in /home/txk6771/expansecluster/spark/spark-env.sh as our slaves file
stopping org.apache.spark.deploy.master.Master
mySpark: Stopping worker on exp-5-29.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark stop org.apache.spark.deploy.worker.Worker 1
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
stopping org.apache.spark.deploy.worker.Worker
mySpark: Stopping worker on exp-5-30.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark stop org.apache.spark.deploy.worker.Worker 1
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
stopping org.apache.spark.deploy.worker.Worker
mySpark: Stopping worker on exp-5-31.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark stop org.apache.spark.deploy.worker.Worker 1
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
stopping org.apache.spark.deploy.worker.Worker
mySpark: Stopping worker on exp-5-32.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark stop org.apache.spark.deploy.worker.Worker 1
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
stopping org.apache.spark.deploy.worker.Worker
mySpark: Stopping worker on exp-5-33.ib.cluster:
  /expanse/lustre/projects/uot166/fegaras/spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh --config /home/txk6771/expansecluster/spark stop org.apache.spark.deploy.worker.Worker 1
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
stopping org.apache.spark.deploy.worker.Worker
Stopping namenodes on [exp-5-29.ib.cluster]
exp-5-29: could not open any host key
exp-5-29: ssh_keysign: no reply
exp-5-29: sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
Stopping datanodes
WARNING: HADOOP_SECURE_DN_PID_DIR has been replaced by HADOOP_SECURE_PID_DIR. Using value of HADOOP_SECURE_DN_PID_DIR.
localhost: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
localhost: @    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
localhost: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
localhost: IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
localhost: Someone could be eavesdropping on you right now (man-in-the-middle attack)!
localhost: It is also possible that a host key has just been changed.
localhost: The fingerprint for the ED25519 key sent by the remote host is
localhost: SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI.
localhost: Please contact your system administrator.
localhost: Add correct host key in /home/txk6771/.ssh/known_hosts to get rid of this message.
localhost: Offending ED25519 key in /home/txk6771/.ssh/known_hosts:1
localhost: Password authentication is disabled to avoid man-in-the-middle attacks.
localhost: Keyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.
localhost: could not open any host key
localhost: ssh_keysign: no reply
localhost: sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
localhost: WARNING: HADOOP_SECURE_DN_PID_DIR has been replaced by HADOOP_SECURE_PID_DIR. Using value of HADOOP_SECURE_DN_PID_DIR.
Stopping secondary namenodes [exp-5-29.ib.cluster]
exp-5-29: could not open any host key
exp-5-29: ssh_keysign: no reply
exp-5-29: sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
Copying Hadoop logs back to /home/txk6771/expansecluster/logs...
'/scratch/txk6771/job_10051764/logs' -> '/home/txk6771/expansecluster/logs'
'/scratch/txk6771/job_10051764/logs/hadoop-txk6771-namenode-exp-5-29.out' -> '/home/txk6771/expansecluster/logs/hadoop-txk6771-namenode-exp-5-29.out'
'/scratch/txk6771/job_10051764/logs/SecurityAuth-txk6771.audit' -> '/home/txk6771/expansecluster/logs/SecurityAuth-txk6771.audit'
'/scratch/txk6771/job_10051764/logs/hadoop-txk6771-datanode-exp-5-29.out' -> '/home/txk6771/expansecluster/logs/hadoop-txk6771-datanode-exp-5-29.out'
'/scratch/txk6771/job_10051764/logs/hadoop-txk6771-namenode-exp-5-29.log' -> '/home/txk6771/expansecluster/logs/hadoop-txk6771-namenode-exp-5-29.log'
'/scratch/txk6771/job_10051764/logs/hadoop-txk6771-datanode-exp-5-29.log' -> '/home/txk6771/expansecluster/logs/hadoop-txk6771-datanode-exp-5-29.log'
'/scratch/txk6771/job_10051764/logs/hadoop-txk6771-secondarynamenode-exp-5-29.out' -> '/home/txk6771/expansecluster/logs/hadoop-txk6771-secondarynamenode-exp-5-29.out'
'/scratch/txk6771/job_10051764/logs/hadoop-txk6771-secondarynamenode-exp-5-29.log' -> '/home/txk6771/expansecluster/logs/hadoop-txk6771-secondarynamenode-exp-5-29.log'
'/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.master.Master-1-exp-5-29.out' -> '/home/txk6771/expansecluster/logs/spark-txk6771-org.apache.spark.deploy.master.Master-1-exp-5-29.out'
'/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-29.out' -> '/home/txk6771/expansecluster/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-29.out'
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
removed '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary/current/VERSION'
removed '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary/current/fsimage_0000000000000000000.md5'
removed '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary/current/fsimage_0000000000000000002'
removed '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary/current/fsimage_0000000000000000000'
removed '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary/current/fsimage_0000000000000000002.md5'
removed '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002'
removed directory '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary/current'
removed directory '/scratch/txk6771/job_10051764/tmp/dfs/namesecondary'
removed directory '/scratch/txk6771/job_10051764/tmp/dfs'
removed directory '/scratch/txk6771/job_10051764/tmp'
removed '/scratch/txk6771/job_10051764/hdfs_data/current/VERSION'
removed directory '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352/tmp'
removed '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352/current/VERSION'
removed directory '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352/current/rbw'
removed '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352/current/dfsUsed'
removed directory '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352/current/finalized'
removed directory '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352/current'
removed '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352/scanner.cursor'
removed directory '/scratch/txk6771/job_10051764/hdfs_data/current/BP-1170934726-198.202.102.242-1646030405352'
removed directory '/scratch/txk6771/job_10051764/hdfs_data/current'
removed directory '/scratch/txk6771/job_10051764/hdfs_data'
removed '/scratch/txk6771/job_10051764/logs/hadoop-txk6771-namenode-exp-5-29.out'
removed '/scratch/txk6771/job_10051764/logs/SecurityAuth-txk6771.audit'
removed '/scratch/txk6771/job_10051764/logs/hadoop-txk6771-datanode-exp-5-29.log'
removed '/scratch/txk6771/job_10051764/logs/hadoop-txk6771-secondarynamenode-exp-5-29.log'
removed '/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-29.out'
removed '/scratch/txk6771/job_10051764/logs/hadoop-txk6771-secondarynamenode-exp-5-29.out'
removed '/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.master.Master-1-exp-5-29.out'
removed '/scratch/txk6771/job_10051764/logs/hadoop-txk6771-datanode-exp-5-29.out'
removed '/scratch/txk6771/job_10051764/logs/hadoop-txk6771-namenode-exp-5-29.log'
removed directory '/scratch/txk6771/job_10051764/logs'
removed '/scratch/txk6771/job_10051764/namenode_data/current/seen_txid'
removed '/scratch/txk6771/job_10051764/namenode_data/current/VERSION'
removed '/scratch/txk6771/job_10051764/namenode_data/current/fsimage_0000000000000000000.md5'
removed '/scratch/txk6771/job_10051764/namenode_data/current/fsimage_0000000000000000000'
removed '/scratch/txk6771/job_10051764/namenode_data/current/edits_inprogress_0000000000000000003'
removed '/scratch/txk6771/job_10051764/namenode_data/current/edits_0000000000000000001-0000000000000000002'
removed directory '/scratch/txk6771/job_10051764/namenode_data/current'
removed directory '/scratch/txk6771/job_10051764/namenode_data'
removed directory '/scratch/txk6771/job_10051764/pids'
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
removed '/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-30.out'
removed directory '/scratch/txk6771/job_10051764/logs'
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
removed '/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-31.out'
removed directory '/scratch/txk6771/job_10051764/logs'
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
removed '/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-32.out'
removed directory '/scratch/txk6771/job_10051764/logs'
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:KEXTXmxlo3gIs/Vs+uYB7GlaTcWGIOSIPMxP5lRi3rI failed
removed '/scratch/txk6771/job_10051764/logs/spark-txk6771-org.apache.spark.deploy.worker.Worker-1-exp-5-33.out'
removed directory '/scratch/txk6771/job_10051764/logs'
